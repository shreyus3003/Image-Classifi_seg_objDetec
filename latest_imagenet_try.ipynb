{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "latest_imagenet_try.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJkIDUeRNIHsi/p0Ts/l23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyus3003/Image-Classifi_seg_objDetec/blob/master/latest_imagenet_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu4nYpLnCZf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5c379ede-583c-4bcc-e3fb-8fa143bc5cf5"
      },
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import glob\n",
        "import pylab as plt\n",
        "import os\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "# importing libraries\n",
        "from matplotlib import pyplot\n",
        "from keras import datasets\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# importing Image class from PIL package  \n",
        "from PIL import Image  \n",
        "\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
        "from keras.models  import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "import random,os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from kerastuner.tuners import RandomSearch\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.utils import print_summary, to_categorical\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "from datetime import datetime\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdUNX0wR7wo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "095e491b-ff08-4999-914b-381368f65dbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnuRYF2nENA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipping the file \n",
        "\n",
        "!unzip /content/drive/My\\ Drive/garbage-classification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsilLSTEiJ_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing and deriving the training images and labelling them\n",
        "trash_images = []\n",
        "labels = [] \n",
        "for fruit_dir_path in glob.glob(\"/content/garbage-classification/Garbage classification/Garbage classification/*/\"):\n",
        "    fruit_label = fruit_dir_path.split(\"/\")[4]\n",
        "    \n",
        "    # Path for reading the files\n",
        "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
        "\n",
        "      # Using cv2 readig the images from path\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Resizing the images\n",
        "        image = cv2.resize(image, (70, 70))\n",
        "\n",
        "        # Colour Transformations \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        trash_images.append(image)\n",
        "        labels.append(fruit_label)\n",
        "        # Appending and deriving the final images \n",
        "\n",
        "trash_images = np.array(trash_images)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58zinSfGiKEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the Key-value dictonaries of the annotations into labels \n",
        "\n",
        "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
        "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUHQ-MzfiKGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_label_id = np.array([label_to_id_dict[i] for i in labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zgIpJlvlQwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f908174-5824-4879-fa4b-e2ea6d965630"
      },
      "source": [
        "# Checking the shape of the data \n",
        "\n",
        "print(\"Train_data shape......:\",trash_images.shape)\n",
        "print(\"Labels shape..........:\",training_label_id.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_data shape......: (2527, 70, 70, 3)\n",
            "Labels shape..........: (2527,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39KRzsDFlwWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into Train and Test\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(trash_images, training_label_id, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-vklch6tc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor Board Integration by giving the approriate log location with the time stamp \n",
        "\n",
        "now = datetime.now()\n",
        "logdir = \"logs/trash_images/\" + now.strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", np.reshape(trainX[0:10],(-2,70,70,3)), step=0)\n",
        "file_writer.set_as_default()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh4E3IZe9q20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path for the image folders\n",
        "\n",
        "dir_path = '/content/garbage-classification/Garbage classification/Garbage classification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJCgLhj9wuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJj0PMHB90EX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "badbf5f6-64c7-42c0-aa9c-8a4a934d2c45"
      },
      "source": [
        "# Checking the Length of the images\n",
        "\n",
        "len(img_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2527"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5268yDn9h_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "03630197-ff54-4f6c-9b6e-6dd1b13c0c10"
      },
      "source": [
        "## ---------Using Image Data Generator below code allows you to do the argumentation on the -----------------\n",
        "##------------ mentioned parameters and sets your image positions---------------------\n",
        "\n",
        "#_------------------- Generating for Train Image------------------\n",
        "train=ImageDataGenerator(horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         validation_split=0.1,\n",
        "                         rescale=1./255,\n",
        "                         shear_range = 0.1,\n",
        "                         zoom_range = 0.1,\n",
        "                         width_shift_range = 0.1,\n",
        "                         height_shift_range = 0.1,)\n",
        "\n",
        "# ------------------Generating for test Image ------------------------\n",
        "\n",
        "test=ImageDataGenerator(rescale=1/255,\n",
        "                        validation_split=0.1)\n",
        "\n",
        "train_generator=train.flow_from_directory(dir_path,\n",
        "                                          target_size=(300,300),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='training')\n",
        "\n",
        "test_generator=test.flow_from_directory(dir_path,\n",
        "                                        target_size=(300,300),\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation')\n",
        "\n",
        "#---------------------------Generating the validation dataset -------------------\n",
        "\n",
        "validation_generator = test.flow_from_directory(\n",
        "    dir_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "print(labels)\n",
        "\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print(labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2276 images belonging to 6 classes.\n",
            "Found 251 images belonging to 6 classes.\n",
            "Found 251 images belonging to 6 classes.\n",
            "{'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n",
            "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXE9QHzk-HkN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de3bf3f9-3c77-4de6-ffcb-79d79c424d2d"
      },
      "source": [
        "# From the generator creating the labels and actual images \n",
        "\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 300, 300, 3), (32, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Z0QT_D-LKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ba3a78e-2f27-45fb-bd98-4d92d57fd072"
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(Labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guaW1GLE-L5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a7a0638d-b0e1-4fab-926e-1cbc97111e21"
      },
      "source": [
        "IMG_SHAPE = (224,224,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4qEQ6AT-V7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwM5XpTC-WnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), #Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNJEPGIq-Wup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "8cf66b8c-490b-4676-83c4-3019930f42a7"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "#----------------------------TRAINING THE MODEL----------------------------------------------\n",
        "\n",
        "history = model.fit_generator(train_generator, \n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs, \n",
        "                              workers=4,\n",
        "                              validation_data=validation_generator, \n",
        "                              validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-f60245109c61>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "71/71 [==============================] - 35s 493ms/step - loss: 0.9728 - accuracy: 0.6488 - val_loss: 0.7145 - val_accuracy: 0.7143\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 38s 540ms/step - loss: 0.5721 - accuracy: 0.7914 - val_loss: 0.5378 - val_accuracy: 0.7768\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 38s 540ms/step - loss: 0.4505 - accuracy: 0.8373 - val_loss: 0.7976 - val_accuracy: 0.7411\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 39s 547ms/step - loss: 0.3901 - accuracy: 0.8663 - val_loss: 0.5571 - val_accuracy: 0.7857\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 39s 546ms/step - loss: 0.3237 - accuracy: 0.8873 - val_loss: 0.4375 - val_accuracy: 0.8304\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 39s 549ms/step - loss: 0.2879 - accuracy: 0.8930 - val_loss: 0.4430 - val_accuracy: 0.8214\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 39s 549ms/step - loss: 0.2517 - accuracy: 0.9118 - val_loss: 0.6370 - val_accuracy: 0.8304\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 39s 553ms/step - loss: 0.2245 - accuracy: 0.9180 - val_loss: 0.3177 - val_accuracy: 0.8571\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 39s 544ms/step - loss: 0.2026 - accuracy: 0.9305 - val_loss: 0.8768 - val_accuracy: 0.7589\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 38s 540ms/step - loss: 0.1833 - accuracy: 0.9349 - val_loss: 0.5885 - val_accuracy: 0.8036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol9N99Hz-hpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGfeLPtK-hyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpKJed3--Wti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA3KmNgZ-Wq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UtoGdp-NXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# SETTING THE SEEDS FOR RANDOM \n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model=tf.keras.Sequential()\n",
        "\n",
        "#------------------------------CONVOLUTIONAL BLOCKS------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "#--------------------------CLASSIFICATION LAYERS--------------------------------\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "#-----------------------------OUTPUT DENSE LAYER-------------------------------\n",
        "model.add(tf.keras.layers.Dense(6,activation='softmax'))\n",
        "\n",
        "# FILEPATH FOR SAVING THE MODEL LOGS\n",
        "filepath=\"/content/trained_model.h5\"\n",
        "logdir=\"logs/trash_images/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#TENSORBOARD INTEGRATION\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# MODEL CHECK POINTS\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"trash_simple_model.h5\", save_best_only=True)\n",
        "callbacks_list = [model_checkpoint,tensorboard_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoRpItrF-RsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b6a3609e-9395-40eb-d7ee-292ca2125b69"
      },
      "source": [
        "#---------------MODEL SUMMARY-------------\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 300, 300, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 150, 150, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 43808)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                2803776   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 2,843,910\n",
            "Trainable params: 2,843,910\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNftt_FGxqXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------PLOTTING THE MODEL AS PNG FILE ------------\n",
        "keras.utils.plot_model(model, \"simple_cnn_trash.png\", show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnJdTFa-WHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------Compiling the model with categorical cross entropy as loss function and \n",
        "#. ADAM as optimiser with acuuracy and Mean Square Error and metrics---------------------------------------\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc','mse']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbjEDQoX-Zlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d21ab89f-3856-4331-f0df-9d905d693892"
      },
      "source": [
        "#---------------- MODEL FITTING WITH EPOCHS, WORKERS, BY INITIATING THE CALL BACKS AND VALIDATION ON DATA---------------------\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=2276//32,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=251//32,\n",
        "                              workers = 4,\n",
        "                              callbacks=callbacks_list) \n",
        "\n",
        "model.predict_generator(test_generator,callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-39230ff6a791>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            "71/71 [==============================] - 329s 5s/step - loss: 1.7062 - acc: 0.2727 - mse: 0.1339 - val_loss: 1.5460 - val_acc: 0.3170 - val_mse: 0.1243\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 330s 5s/step - loss: 1.6120 - acc: 0.3048 - mse: 0.1278 - val_loss: 1.5961 - val_acc: 0.3214 - val_mse: 0.1263\n",
            "Epoch 3/10\n",
            "68/71 [===========================>..] - ETA: 13s - loss: 1.5207 - acc: 0.3524 - mse: 0.1215"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VKK6PRSIrrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "88b53a91-d67e-49ce-b8a3-99b710c58834"
      },
      "source": [
        "#------------PRINTING THE LEARNING RATE USED----------------------\n",
        "print(K.eval(model.optimizer.lr))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}